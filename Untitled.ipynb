{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from tcn import TemporalConvNet\n",
    "import time\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.environ['MYDATA_DIR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_c = data.Data(wd=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_x, raw_y = data_c.data(class_num=19, data_num=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7600,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7600, 125, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "seq_len = 125\n",
    "epochs = 50\n",
    "iters = 100\n",
    "T = 130\n",
    "n_steps = T + (2 * seq_len)\n",
    "n_classes = 10  # Digits 0 - 9\n",
    "n_train = 10000\n",
    "n_test = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(760, 125, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(raw_x, raw_y, test_size=0.90, random_state=0)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = X_train\n",
    "y_train_new = y_train\n",
    "for i,j in zip(X_train,y_train):\n",
    "    X_train_new = np.append(X_train_new,i+np.random.normal(0, 1, (125, 3)).reshape(1,125,3))\n",
    "    y_train_new = np.append(y_train_new, j)\n",
    "X_train = X_train_new.reshape(-1,125,3)\n",
    "y_train = y_train_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mytcn(nn.Module):\n",
    "    def __init__(self, num_inputs,num_outputs ,num_channels, kernel_size=2, dropout=0.2):\n",
    "        super(Mytcn, self).__init__()\n",
    "        self.tcn = TemporalConvNet(num_inputs=num_inputs, num_channels=num_channels, kernel_size=kernel_size, dropout=dropout)\n",
    "        self.linear = nn.Linear(num_channels[-1], num_outputs)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.linear.weight.data.normal_(1, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.tcn(x)\n",
    "        \n",
    "#         return  self.linear(y.transpose(1, 2))\n",
    "        return F.softmax(self.linear(y[:, :, -1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_chans = [4] * (4) \n",
    "model = Mytcn(num_inputs=raw_x.shape[1],num_outputs=19, num_channels=num_chans, kernel_size=8, dropout=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mizunomi/.pyenv/versions/anaconda3-5.2.0/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 19])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.tensor(raw_x[0:100],dtype=torch.float32)\n",
    "model(input).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.001\n",
    "optimizer =optim.RMSprop(model.parameters(),lr=lr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "total_loss = 0\n",
    "start_time = time.time()\n",
    "correct = 0\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RMSprop (\n",
       "Parameter Group 0\n",
       "    alpha: 0.99\n",
       "    centered: False\n",
       "    eps: 1e-08\n",
       "    lr: 0.001\n",
       "    momentum: 0\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mizunomi/.pyenv/versions/anaconda3-5.2.0/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(2.9453, grad_fn=<NllLossBackward>)\n",
      "50 tensor(2.7689, grad_fn=<NllLossBackward>)\n",
      "100 tensor(2.7323, grad_fn=<NllLossBackward>)\n",
      "150 tensor(2.7048, grad_fn=<NllLossBackward>)\n",
      "200 tensor(2.6891, grad_fn=<NllLossBackward>)\n",
      "250 tensor(2.6770, grad_fn=<NllLossBackward>)\n",
      "300 tensor(2.6676, grad_fn=<NllLossBackward>)\n",
      "350 tensor(2.6650, grad_fn=<NllLossBackward>)\n",
      "400 tensor(2.6613, grad_fn=<NllLossBackward>)\n",
      "450 tensor(2.6572, grad_fn=<NllLossBackward>)\n",
      "500 tensor(2.6500, grad_fn=<NllLossBackward>)\n",
      "550 tensor(2.6430, grad_fn=<NllLossBackward>)\n",
      "600 tensor(2.6373, grad_fn=<NllLossBackward>)\n",
      "650 tensor(2.6341, grad_fn=<NllLossBackward>)\n",
      "700 tensor(2.6345, grad_fn=<NllLossBackward>)\n",
      "750 tensor(2.6280, grad_fn=<NllLossBackward>)\n",
      "800 tensor(2.6244, grad_fn=<NllLossBackward>)\n",
      "850 tensor(2.6185, grad_fn=<NllLossBackward>)\n",
      "900 tensor(2.6108, grad_fn=<NllLossBackward>)\n",
      "950 tensor(2.6075, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.tensor(X_train,dtype=torch.float32)\n",
    "labels = torch.tensor(y_train,dtype=torch.long)\n",
    "for i in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    out= model(input)\n",
    "    loss = criterion(out, labels)\n",
    "    if i%50==0:\n",
    "#         input = torch.tensor([X_train[1]],dtype=torch.float32)\n",
    "#         out= model(input)\n",
    "#         print(out)\n",
    "#         print(torch.max(out, 1))\n",
    "        print(i,loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mizunomi/.pyenv/versions/anaconda3-5.2.0/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2754385964912281"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.tensor(X_test,dtype=torch.float32)\n",
    "out= model(input)\n",
    "\n",
    "a,b =torch.max(out, 1)\n",
    "l=torch.tensor(y_test,dtype=torch.long)\n",
    "acc=(b == l).sum().item()/len(b)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mizunomi/.pyenv/versions/anaconda3-5.2.0/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4355263157894737"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.tensor(X_train,dtype=torch.float32)\n",
    "out= model(input)\n",
    "\n",
    "a,b =torch.max(out, 1)\n",
    "l=torch.tensor(y_train,dtype=torch.long)\n",
    "acc=(b == l).sum().item()/len(b)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
